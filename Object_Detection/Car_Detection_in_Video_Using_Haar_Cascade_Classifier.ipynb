{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcde855d-a692-444c-a683-5bdb8ef6bf05",
   "metadata": {},
   "source": [
    "## **Car Detection in Video Using Haar Cascade Classifier**\n",
    "\n",
    "###  Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3f8fe9-d472-406e-be80-24c66341aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8806f9b-7019-4af3-badb-fa548fed1b66",
   "metadata": {},
   "source": [
    "These libraries are necessary for processing the video and performing object detection.\n",
    "- time is used for adding small delays between processing frames to prevent system overload.\n",
    "- cv2 is the OpenCV library, used for reading and processing the video and performing car detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b82129-f7fb-4345-91a1-e6edbde652af",
   "metadata": {},
   "source": [
    "**Loading the Pre-trained Car Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa19329e-2900-4252-ab33-1e56d24fea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_classifier = cv2.CascadeClassifier(\"haarcascade_car.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ccb3d-26a9-42ea-9d30-1fb8636a6adb",
   "metadata": {},
   "source": [
    "- This line loads the pre-trained Haar Cascade classifier for detecting cars. Haar classifiers are used to detect objects like cars, faces, or pedestrians in an image by analyzing patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3778d-95e4-402a-8824-a69f531e84ea",
   "metadata": {},
   "source": [
    "**Opening the Video File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb566a0-33a0-47e5-9320-a0f1cbce9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('cars_video.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a008c3-15fb-4c5c-a759-1b23a6186cab",
   "metadata": {},
   "source": [
    "- This opens the video file cars_video.avi for processing. The cap object allows us to read frames from the video one at a time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92998123-bf3a-4f12-b3f1-3eaf9e2b1630",
   "metadata": {},
   "source": [
    "**Processing the Video in a Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebee54e0-8927-4f51-b607-4f9d6855a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    time.sleep(0.05)  # Sleep for a short time to avoid overloading the system\n",
    "    \n",
    "    # Read the first frame\n",
    "    check, frame = cap.read()\n",
    "    if not check:  # If frame not read correctly, exit loop\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Pass the frame to our classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "\n",
    "    # Extract bounding boxes for any cars identified\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "        cv2.imshow('cars', frame)\n",
    "\n",
    "    # Exit condition when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c543221-2feb-40ce-bcdf-b37f27e71b08",
   "metadata": {},
   "source": [
    "- Processing the Video: The video is opened for processing using cap = cv2.VideoCapture(). The loop while cap.isOpened() runs continuously as long as the video file is successfully loaded and being processed. Inside the loop, the system reads individual frames from the video and processes them one at a time. The time.sleep(0.05) is used to avoid overloading the system by slowing down the frame processing slightly.\n",
    "- Reading Each Frame: For each frame of the video, the system attempts to capture it using check, frame = cap.read(). If the frame cannot be read correctly (i.e., check is False), the loop breaks, ending the video processing. Otherwise, the frame is passed on for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06348408-0325-4425-b8c4-08a20028e726",
   "metadata": {},
   "source": [
    "- Converting to Grayscale: To simplify the detection process, the captured frame is converted from color (BGR) to grayscale. This is done using cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY). Grayscale images are computationally simpler to process and are often used in object detection tasks.\n",
    "- Detecting Cars in the Frame: The car_classifier.detectMultiScale(gray, 1.4, 2) function is responsible for detecting cars in the grayscale image. The function uses the Haar Cascade Classifier to identify potential cars based on trained patterns. The parameters provided (1.4 and 2) control the scale of the image and the minimum number of neighboring rectangles required for a valid detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5b002-898e-497f-8f2e-f70b4e910fae",
   "metadata": {},
   "source": [
    "- Drawing Bounding Boxes Around Detected Cars: For each car detected, the system draws a bounding box around it using cv2.rectangle(). The coordinates of the box are derived from the detection result, which gives the position and size of the car in the frame. These bounding boxes are drawn in yellow, and the frame with the bounding boxes is displayed using cv2.imshow().\n",
    "- Exiting the Video Processing: The loop will continue to process frames until the user presses the 'q' key. The cv2.waitKey(1) function listens for key presses, and if the 'q' key is pressed, the loop is exited, and the program stops.\n",
    "- Releasing Resources and Closing Windows: After processing the video, the system releases the video capture object and closes all OpenCV windows using cap.release() and cv2.destroyAllWindows() to free up system resources.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafa517-dfb9-44f3-a2d4-1af0c25a80c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e82b6cf-7652-4772-b197-619d4d570bed",
   "metadata": {},
   "source": [
    "### **Project by : SIREESHA RAGIPATI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d905f93-18ee-485a-9d23-c5dcac37d084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
